# Pure Rust Alternative to PM2/Node.js

**Your Situation:**
- âœ… Stayed pure Rust (RepoAgent, Agent Mesh, Linear Agent, Forge)
- âš ï¸ PM2 brings in Node.js dependency
- ğŸ¯ Want pure Rust alternative for the future

---

## ğŸ¦€ **RUST ALTERNATIVES TO PM2**

### **Option 1: systemd (Native OS-Level) - RECOMMENDED**
**Best for:** Production Linux deployments

**What it is:**
- Built into most Linux distros
- Native process manager
- No Node.js, No Rust - Pure OS
- Industry standard

**Setup:**
```bash
# Create systemd service for each CTAS service
sudo nano /etc/systemd/system/ctas-repoagent.service
```

```ini
[Unit]
Description=CTAS RepoAgent Gateway
After=network.target

[Service]
Type=simple
User=ctas7
WorkingDirectory=/Users/cp5337/Developer/ctas-7-shipyard-staging/ctas7-repoagent
ExecStart=/Users/cp5337/Developer/ctas-7-shipyard-staging/ctas7-repoagent/target/release/gateway
Restart=always
RestartSec=10
StandardOutput=journal
StandardError=journal
Environment="CTAS_API_KEY=your-key"
Environment="RUST_LOG=info"

[Install]
WantedBy=multi-user.target
```

**Commands:**
```bash
# Start service
sudo systemctl start ctas-repoagent

# Enable on boot
sudo systemctl enable ctas-repoagent

# View status
sudo systemctl status ctas-repoagent

# View logs
sudo journalctl -u ctas-repoagent -f

# View all CTAS services
systemctl list-units 'ctas-*'
```

**Pros:**
- âœ… Pure Rust services, no Node.js
- âœ… Industry standard
- âœ… OS-level integration
- âœ… Excellent logging (journald)
- âœ… Dependency management
- âœ… Auto-restart on crash
- âœ… Resource limits

**Cons:**
- âŒ Linux only (not macOS native)
- âŒ Less "dashboard-y" than PM2
- âŒ Requires sudo/root access

---

### **Option 2: Build Your Own Rust Service Manager** ğŸ¦€
**Best for:** Complete control, CTAS-native solution

**Architecture:**
```rust
// ctas7-service-orchestrator/src/main.rs

use tokio::process::Command;
use tokio::task::JoinHandle;
use std::collections::HashMap;
use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Serialize, Deserialize)]
struct ServiceConfig {
    name: String,
    command: String,
    args: Vec<String>,
    cwd: String,
    env: HashMap<String, String>,
    port: u16,
    auto_restart: bool,
    max_restarts: usize,
}

struct ServiceManager {
    services: HashMap<String, Service>,
}

struct Service {
    config: ServiceConfig,
    handle: Option<JoinHandle<()>>,
    restarts: usize,
    status: ServiceStatus,
}

#[derive(Debug, Clone)]
enum ServiceStatus {
    Running,
    Stopped,
    Crashed,
    Restarting,
}

impl ServiceManager {
    pub async fn new(config_path: &str) -> anyhow::Result<Self> {
        // Load services from TOML config
        let config: Vec<ServiceConfig> = toml::from_str(&std::fs::read_to_string(config_path)?)?;

        let mut services = HashMap::new();
        for cfg in config {
            services.insert(cfg.name.clone(), Service {
                config: cfg,
                handle: None,
                restarts: 0,
                status: ServiceStatus::Stopped,
            });
        }

        Ok(Self { services })
    }

    pub async fn start_all(&mut self) -> anyhow::Result<()> {
        for (name, service) in &mut self.services {
            self.start_service(name).await?;
        }
        Ok(())
    }

    pub async fn start_service(&mut self, name: &str) -> anyhow::Result<()> {
        let service = self.services.get_mut(name).ok_or(anyhow::anyhow!("Service not found"))?;

        let config = service.config.clone();
        let handle = tokio::spawn(async move {
            loop {
                let mut cmd = Command::new(&config.command);
                cmd.args(&config.args)
                   .current_dir(&config.cwd);

                for (k, v) in &config.env {
                    cmd.env(k, v);
                }

                println!("ğŸš€ Starting service: {}", config.name);

                match cmd.spawn() {
                    Ok(mut child) => {
                        match child.wait().await {
                            Ok(status) => {
                                println!("âš ï¸  Service {} exited: {:?}", config.name, status);
                            }
                            Err(e) => {
                                println!("âŒ Service {} error: {}", config.name, e);
                            }
                        }
                    }
                    Err(e) => {
                        println!("âŒ Failed to start {}: {}", config.name, e);
                    }
                }

                if !config.auto_restart {
                    break;
                }

                println!("ğŸ”„ Restarting {} in 5s...", config.name);
                tokio::time::sleep(tokio::time::Duration::from_secs(5)).await;
            }
        });

        service.handle = Some(handle);
        service.status = ServiceStatus::Running;

        Ok(())
    }

    pub async fn stop_service(&mut self, name: &str) -> anyhow::Result<()> {
        if let Some(service) = self.services.get_mut(name) {
            if let Some(handle) = service.handle.take() {
                handle.abort();
                service.status = ServiceStatus::Stopped;
            }
        }
        Ok(())
    }

    pub fn status(&self) -> Vec<ServiceInfo> {
        self.services.iter().map(|(name, service)| {
            ServiceInfo {
                name: name.clone(),
                status: format!("{:?}", service.status),
                restarts: service.restarts,
                port: service.config.port,
            }
        }).collect()
    }
}

#[derive(Debug, Serialize)]
struct ServiceInfo {
    name: String,
    status: String,
    restarts: usize,
    port: u16,
}

// REST API for monitoring (like pm2 status)
#[tokio::main]
async fn main() -> anyhow::Result<()> {
    let mut manager = ServiceManager::new("services.toml").await?;

    // Start all services
    manager.start_all().await?;

    // HTTP API for status
    use axum::{Router, routing::get, Json};

    let app = Router::new()
        .route("/status", get(|| async {
            // Return service status
            Json(manager.status())
        }));

    let listener = tokio::net::TcpListener::bind("0.0.0.0:19000").await?;
    axum::serve(listener, app).await?;

    Ok(())
}
```

**Config File (services.toml):**
```toml
[[service]]
name = "repoagent-gateway"
command = "cargo"
args = ["run", "--release", "--bin", "gateway"]
cwd = "/Users/cp5337/Developer/ctas-7-shipyard-staging/ctas7-repoagent"
port = 15180
auto_restart = true
max_restarts = 10

[service.env]
CTAS_API_KEY = "your-key"
RUST_LOG = "info"

[[service]]
name = "linear-agent"
command = "cargo"
args = ["run", "--release"]
cwd = "/Users/cp5337/Developer/ctas-7-shipyard-staging/ctas7-linear-agent-rust"
port = 18180
auto_restart = true
max_restarts = 10

[service.env]
LINEAR_API_KEY = "your-key"
RUST_LOG = "info"
```

**Pros:**
- âœ… Pure Rust, no Node.js
- âœ… Complete control
- âœ… CTAS-native
- âœ… Can add CTAS-specific features
- âœ… Integrates with Foundation Core
- âœ… Cross-platform (macOS, Linux, Windows)

**Cons:**
- âš ï¸ Need to build and maintain it
- âš ï¸ Less mature than PM2/systemd

---

### **Option 3: Single Binary with Tokio** ğŸ¦€
**Best for:** Simplicity, fewer moving parts

**Concept:**
Run all services in **ONE Rust binary** using tokio tasks:

```rust
// ctas7-unified-runtime/src/main.rs

use tokio::task::JoinSet;

#[tokio::main]
async fn main() -> anyhow::Result<()> {
    let mut set = JoinSet::new();

    // Start RepoAgent Gateway
    set.spawn(async {
        ctas7_repoagent::gateway::run().await
    });

    // Start Agent Mesh
    set.spawn(async {
        ctas7_repoagent::agent_mesh::run_all().await
    });

    // Start Linear Agent
    set.spawn(async {
        ctas7_linear_agent::run().await
    });

    // Start Forge
    set.spawn(async {
        ctas7_forge::run().await
    });

    // Wait for all services
    while let Some(res) = set.join_next().await {
        if let Err(e) = res {
            eprintln!("Service error: {:?}", e);
        }
    }

    Ok(())
}
```

**Pros:**
- âœ… Pure Rust, no Node.js
- âœ… Single binary
- âœ… Shared memory between services
- âœ… Tokio handles async
- âœ… Simple deployment

**Cons:**
- âš ï¸ All services crash together
- âš ï¸ No isolation
- âš ï¸ Harder to restart individual services

---

### **Option 4: Use Existing Rust Tools**

#### **A. cargo-watch (Development)**
```bash
# Auto-restart on file changes
cargo watch -x 'run --release --bin gateway'
```

#### **B. systemfd + listenfd (Socket activation)**
```bash
# Zero-downtime restarts
systemfd --no-pid -s http::15180 -- cargo watch -x run
```

#### **C. Custom Smart Crate Orchestrator**
You already have Smart Crate system! Extend it:

```rust
// ctas7-smart-crate-orchestrator
// Manages multiple crates as services
```

---

## ğŸ“Š **COMPARISON**

| Solution | Pure Rust | Cross-Platform | Maturity | Control | Complexity |
|----------|-----------|----------------|----------|---------|------------|
| **systemd** | âœ… (services) | âŒ Linux only | â­â­â­â­â­ | â­â­â­ | â­â­ |
| **Custom Manager** | âœ…âœ…âœ… | âœ… | â­â­ | â­â­â­â­â­ | â­â­â­â­ |
| **Single Binary** | âœ…âœ…âœ… | âœ… | â­â­â­ | â­â­â­ | â­â­ |
| **PM2** | âŒ (Node.js) | âœ… | â­â­â­â­â­ | â­â­â­ | â­ |

---

## ğŸ¯ **RECOMMENDATION FOR CTAS**

### **Phase 1: Use PM2 Now** âœ…
You already have it configured:
```bash
cd /Users/cp5337/Developer/ctas7-command-center
./START_ALL_SERVICES.sh
```

**Why:** Get everything running TODAY

---

### **Phase 2: Build CTAS Service Orchestrator** ğŸ¦€
Create: `ctas7-service-orchestrator`

**Features:**
- Pure Rust
- TOML config
- HTTP API for status
- Foundation Core integration
- Trivariate hash for service IDs
- Smart Crate aware
- Neural Mux integration

**Location:**
```
/Users/cp5337/Developer/ctas-7-shipyard-staging/ctas7-service-orchestrator/
â”œâ”€â”€ Cargo.toml
â”œâ”€â”€ services.toml (config)
â””â”€â”€ src/
    â”œâ”€â”€ main.rs (orchestrator)
    â”œâ”€â”€ service.rs (service management)
    â”œâ”€â”€ monitor.rs (health checks)
    â””â”€â”€ api.rs (HTTP status API)
```

---

### **Phase 3: Production with systemd** ğŸ§
For Linux production deployments:
```bash
# Generate systemd units from your Rust orchestrator
ctas7-service-orchestrator generate-systemd
```

---

## ğŸš€ **IMMEDIATE ACTION PLAN**

### **Today: Use PM2**
```bash
# You're not "breaking" pure Rust
# PM2 just manages the processes
# Your code is still pure Rust!
./START_ALL_SERVICES.sh
```

### **This Week: Design CTAS Orchestrator**
```bash
# Create new crate
cd /Users/cp5337/Developer/ctas-7-shipyard-staging
cargo new ctas7-service-orchestrator
```

### **Next Week: Build CTAS Orchestrator**
Implement the Rust service manager shown above

### **Future: Replace PM2**
```bash
# Pure Rust orchestrator
ctas7-service-orchestrator start-all

# View status (like pm2 status)
ctas7-service-orchestrator status

# Beautiful TUI dashboard
ctas7-service-orchestrator monitor
```

---

## ğŸ’¡ **THE VISION**

### **CTAS Native Service Orchestrator:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CTAS-7 Service Orchestrator (Pure Rust)   â”‚
â”‚  Port: 19000                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ RepoAgent    â”‚  â”‚ Linear Agent â”‚       â”‚
â”‚  â”‚ Status: âœ…   â”‚  â”‚ Status: âœ…   â”‚       â”‚
â”‚  â”‚ Port: 15180  â”‚  â”‚ Port: 18180  â”‚       â”‚
â”‚  â”‚ Uptime: 2h   â”‚  â”‚ Uptime: 2h   â”‚       â”‚
â”‚  â”‚ Restarts: 0  â”‚  â”‚ Restarts: 0  â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ Agent Mesh   â”‚  â”‚ Forge        â”‚       â”‚
â”‚  â”‚ Status: âœ…   â”‚  â”‚ Status: âœ…   â”‚       â”‚
â”‚  â”‚ Port: 50055  â”‚  â”‚ Port: 18220  â”‚       â”‚
â”‚  â”‚ Agents: 7/7  â”‚  â”‚ Tasks: 12    â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                             â”‚
â”‚  Foundation Core: âœ…                       â”‚
â”‚  Neural Mux: âœ…                            â”‚
â”‚  Trivariate Hashing: âœ…                    â”‚
â”‚  Smart Crate System: âœ…                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ **SUMMARY**

**You're right to want pure Rust!** Options:

1. **Now:** Use PM2 (pragmatic, get running today)
2. **Soon:** Build `ctas7-service-orchestrator` (pure Rust)
3. **Production:** systemd on Linux
4. **Ultimate:** CTAS Native Orchestrator with TUI

**All your services are ALREADY pure Rust** - PM2 just manages them. You haven't "broken" your purity - you're just using a practical tool for process management.

**Want me to scaffold `ctas7-service-orchestrator` now?** ğŸ¦€
